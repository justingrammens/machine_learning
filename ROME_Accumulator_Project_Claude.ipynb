{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/justingrammens/machine_learning/blob/master/ROME_Accumulator_Project_Claude.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accumulator Block Verilog Generation\n",
        "\n",
        "This notebook uses the ROME (Rectification of Output through Multiple Executions) framework to generate Verilog modules for the Accumulator signal processing block.\n",
        "\n",
        "Based on HWRS requirements including:\n",
        "- Configurable signal source selection (HWRS511914)\n",
        "- Rectification and accumulation (HWRS511916)\n",
        "- SRA calculation with configurable divisor (HWRS512400-512405)\n",
        "- Warmup delay period (HWRS512403)\n",
        "- Maskable SRA interrupt (HWRS512406)\n",
        "- Parity protection on config registers (ICDS511907)"
      ],
      "metadata": {
        "id": "arc_em6_intro"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initial Setup"
      ],
      "metadata": {
        "id": "XsbbXgjNAdy9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-ll5GZeKMwa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e76b9573-0c4e-48e4-837a-c1526aec0550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.12/dist-packages (2.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from openai) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.12/dist-packages (from openai) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\n",
            "Collecting anthropic\n",
            "  Downloading anthropic-0.75.0-py3-none-any.whl.metadata (28 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.12.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.9.0)\n",
            "Requirement already satisfied: docstring-parser<1,>=0.15 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.17.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (0.12.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from anthropic) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from anthropic) (4.15.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->anthropic) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.25.0->anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->anthropic) (0.4.2)\n",
            "Downloading anthropic-0.75.0-py3-none-any.whl (388 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m388.2/388.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: anthropic\n",
            "Successfully installed anthropic-0.75.0\n",
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:6 https://cli.github.com/packages stable InRelease\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [69.3 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,411 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,965 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [114 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [40.3 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,633 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,205 kB]\n",
            "Get:18 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,551 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,851 kB]\n",
            "Fetched 34.8 MB in 8s (4,470 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  gtkwave\n",
            "The following NEW packages will be installed:\n",
            "  iverilog\n",
            "0 upgraded, 1 newly installed, 0 to remove and 3 not upgraded.\n",
            "Need to get 2,130 kB of archives.\n",
            "After this operation, 6,749 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 iverilog amd64 11.0-1.1 [2,130 kB]\n",
            "Fetched 2,130 kB in 0s (8,077 kB/s)\n",
            "Selecting previously unselected package iverilog.\n",
            "(Reading database ... 117528 files and directories currently installed.)\n",
            "Preparing to unpack .../iverilog_11.0-1.1_amd64.deb ...\n",
            "Unpacking iverilog (11.0-1.1) ...\n",
            "Setting up iverilog (11.0-1.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "#@title Setting up the notebook\n",
        "\n",
        "### Installing dependencies\n",
        "!pip install openai\n",
        "!pip install anthropic\n",
        "!apt-get update\n",
        "!apt-get install -y iverilog"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select Model\n",
        "#define the model to be used\n",
        "model_choice = \"gpt-5.2-2025-12-11\"\n",
        "\n",
        "#model_choice = \"claude-3-7-sonnet-20250219\"\n",
        "#model_choice = \"gemini-2.5-flash-preview-04-17\"\n",
        "#model_choice = \"gemini-2.5-flash\""
      ],
      "metadata": {
        "id": "jzb7Hu4aPeuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lk5cP5x12z9u"
      },
      "outputs": [],
      "source": [
        "#@title Utility functions\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import openai\n",
        "import anthropic\n",
        "import subprocess\n",
        "import time\n",
        "import numpy as np\n",
        "from abc import ABC, abstractmethod\n",
        "import re\n",
        "from google.colab import userdata\n",
        "\n",
        "# Try to import Gemini, but don't fail if not available\n",
        "try:\n",
        "    import google.genai.errors\n",
        "    from google import genai\n",
        "    from google.genai import types\n",
        "    GEMINI_AVAILABLE = True\n",
        "except ImportError:\n",
        "    GEMINI_AVAILABLE = False\n",
        "    print(\"Gemini not available - install google-genai if needed\")\n",
        "\n",
        "\n",
        "################################################################################\n",
        "### LOGGING\n",
        "################################################################################\n",
        "# Allows us to log the output of the model to a file if logging is enabled\n",
        "class LogStdoutToFile:\n",
        "    def __init__(self, filename):\n",
        "        self._filename = filename\n",
        "        self._original_stdout = sys.stdout\n",
        "\n",
        "    def __enter__(self):\n",
        "        if self._filename:\n",
        "            sys.stdout = open(self._filename, 'w')\n",
        "        return self\n",
        "\n",
        "    def __exit__(self, exc_type, exc_value, traceback):\n",
        "        if self._filename:\n",
        "            sys.stdout.close()\n",
        "        sys.stdout = self._original_stdout\n",
        "\n",
        "\n",
        "################################################################################\n",
        "### CONVERSATION CLASS\n",
        "# allows us to abstract away the details of the conversation for use with\n",
        "# different LLM APIs\n",
        "################################################################################\n",
        "\n",
        "class Conversation:\n",
        "    def __init__(self, log_file=None):\n",
        "        self.messages = []\n",
        "        self.log_file = log_file\n",
        "\n",
        "        if self.log_file and os.path.exists(self.log_file):\n",
        "            open(self.log_file, 'w').close()\n",
        "\n",
        "    def add_message(self, role, content):\n",
        "        \"\"\"Add a new message to the conversation.\"\"\"\n",
        "        self.messages.append({'role': role, 'content': content})\n",
        "\n",
        "        if self.log_file:\n",
        "            with open(self.log_file, 'a') as file:\n",
        "                file.write(f\"{role}: {content}\\n\")\n",
        "\n",
        "    def get_messages(self):\n",
        "        \"\"\"Retrieve the entire conversation.\"\"\"\n",
        "        return self.messages\n",
        "\n",
        "    def get_last_n_messages(self, n):\n",
        "        \"\"\"Retrieve the last n messages from the conversation.\"\"\"\n",
        "        return self.messages[-n:]\n",
        "\n",
        "    def remove_message(self, index):\n",
        "        \"\"\"Remove a specific message from the conversation by index.\"\"\"\n",
        "        if index < len(self.messages):\n",
        "            del self.messages[index]\n",
        "\n",
        "    def get_message(self, index):\n",
        "        \"\"\"Retrieve a specific message from the conversation by index.\"\"\"\n",
        "        return self.messages[index] if index < len(self.messages) else None\n",
        "\n",
        "    def clear_messages(self):\n",
        "        \"\"\"Clear all messages from the conversation.\"\"\"\n",
        "        self.messages = []\n",
        "\n",
        "    def __str__(self):\n",
        "        \"\"\"Return the conversation in a string format.\"\"\"\n",
        "        return \"\\n\".join([f\"{msg['role']}: {msg['content']}\" for msg in self.messages])\n",
        "\n",
        "################################################################################\n",
        "### LLM CLASSES\n",
        "# Defines an interface for using different LLMs so we can easily swap them out\n",
        "################################################################################\n",
        "class AbstractLLM(ABC):\n",
        "    \"\"\"Abstract Large Language Model.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def generate(self, conversation: Conversation):\n",
        "        \"\"\"Generate a response based on the given conversation.\"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "class ChatGPT(AbstractLLM):\n",
        "    \"\"\"ChatGPT Large Language Model.\"\"\"\n",
        "\n",
        "    def __init__(self, model_id=model_choice):\n",
        "        super().__init__()\n",
        "        # Get the key from environment variable (set once at startup)\n",
        "        api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
        "        if api_key is None:\n",
        "            raise ValueError(\"No API key found. Set OPENAI_API_KEY in the API Key Configuration cell.\")\n",
        "\n",
        "        self.client = openai.OpenAI(api_key=api_key)\n",
        "        self.model_id = model_id\n",
        "\n",
        "    def generate(self, conversation: Conversation, num_choices=1):\n",
        "        messages = [{\"role\" : \"user\", \"content\" : msg[\"content\"]} for msg in conversation.get_messages()]\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model_id,\n",
        "            messages = messages,\n",
        "        )\n",
        "\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "class Claude(AbstractLLM):\n",
        "      def __init__(self, model_id=model_choice):\n",
        "        super().__init__()\n",
        "        self.client = anthropic.Anthropic(api_key=os.environ['CLAUDE_API_KEY'])\n",
        "        self.model_id = model_id\n",
        "\n",
        "      def generate(self, conversation: Conversation, num_choices=1):\n",
        "        base_delay = 2\n",
        "        max_retries = 20\n",
        "        for attempt in range(1, max_retries + 1):\n",
        "          try:\n",
        "            output = self.client.messages.create(\n",
        "                      model=model_choice,\n",
        "                      max_tokens=16384,\n",
        "                      messages=[{\"role\" : msg[\"role\"], \"content\" : msg[\"content\"]} for msg in conversation.get_messages()]\n",
        "                  ).content[0].text\n",
        "            return output\n",
        "          except (Exception) as e:\n",
        "            wait_time = base_delay * (2 ** (attempt - 1))\n",
        "            print(f\"[Retry {attempt}/{max_retries}] API error: {e}. Retrying in {wait_time:.1f} seconds...\")\n",
        "            time.sleep(wait_time)\n",
        "          except Exception as e:\n",
        "            print(f\"[Error] Unexpected exception: {e}\")\n",
        "            return 0\n",
        "        print(f\"Failed, exceeded max retries {max_retries}\")\n",
        "        return 0\n",
        "\n",
        "class Gemini(AbstractLLM):\n",
        "      def __init__(self, model_id=model_choice):\n",
        "        super().__init__()\n",
        "        if not GEMINI_AVAILABLE:\n",
        "            raise ImportError(\"Gemini not available\")\n",
        "        self.gemini_client = genai.Client(api_key=os.environ['GEMINI_API_KEY'])\n",
        "        self.model_id = model_id\n",
        "\n",
        "      def generate(self, conversation: Conversation, num_choices=1):\n",
        "\n",
        "          output = self.gemini_client.models.generate_content(\n",
        "                        model=model_choice,\n",
        "                        contents=[msg[\"content\"] for msg in conversation.get_messages()],\n",
        "                        config=types.GenerateContentConfig(\n",
        "                            max_output_tokens=16384,\n",
        "                            temperature=0.6,\n",
        "                            topP=0.95,\n",
        "                        )\n",
        "                    ).text\n",
        "          return output\n",
        "\n",
        "################################################################################\n",
        "### PARSING AND TEXT MANIPULATION FUNCTIONS\n",
        "################################################################################\n",
        "def find_verilog_modules(markdown_string, module_name='top_module'):\n",
        "    \"\"\"Find all Verilog modules in text using a robust approach.\"\"\"\n",
        "\n",
        "    modules = []\n",
        "\n",
        "    # Find all 'module' keyword positions\n",
        "    module_starts = [m.start() for m in re.finditer(r'\\bmodule\\b', markdown_string)]\n",
        "\n",
        "    for start in module_starts:\n",
        "        # Find the next 'endmodule' after this 'module'\n",
        "        end_match = re.search(r'\\bendmodule\\b', markdown_string[start:])\n",
        "        if end_match:\n",
        "            end = start + end_match.end()\n",
        "            module_text = markdown_string[start:end]\n",
        "\n",
        "            # Verify it looks like a valid module (has module name)\n",
        "            if re.match(r'module\\s+\\w+', module_text):\n",
        "                modules.append(module_text)\n",
        "\n",
        "    return modules  # (with deduplication)\n",
        "\n",
        "\n",
        "def write_code_blocks_to_file(markdown_string, module_name, filename):\n",
        "    code_match = find_verilog_modules(markdown_string, module_name)\n",
        "\n",
        "    if not code_match:\n",
        "        print(\"No code blocks found in response\")\n",
        "        exit(3)\n",
        "\n",
        "    with open(filename, 'w') as file:\n",
        "        for code_block in code_match:\n",
        "            file.write(code_block)\n",
        "            file.write('\\n')\n",
        "\n",
        "def generate_verilog(conv, model_type, model_id=\"\"):\n",
        "    if model_type == \"ChatGPT\":\n",
        "        model = ChatGPT()\n",
        "    elif model_type == \"Claude\":\n",
        "        model = Claude()\n",
        "    elif model_type == \"Gemini\":\n",
        "        model = Gemini()\n",
        "    else:\n",
        "        raise ValueError(\"Invalid model type\")\n",
        "    return(model.generate(conv))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrzwitIm3N3i"
      },
      "outputs": [],
      "source": [
        "#@title Feedback Loop\n",
        "\n",
        "def verilog_loop(design_prompt, module, testbench, max_iterations, model_type, outdir=\"\", log=None, prev_module=None):\n",
        "    \"\"\"Generate and iteratively refine a Verilog module until it passes testbench.\"\"\"\n",
        "\n",
        "    if outdir != \"\":\n",
        "        outdir = outdir + \"/\"\n",
        "\n",
        "    conv = Conversation(log_file=log)\n",
        "    if model_type == \"ChatGPT\":\n",
        "      conv.add_message(\"system\", \"You are an autocomplete engine for Verilog code. \\\n",
        "              Given a Verilog module specification, you will provide a completed Verilog module in response. \\\n",
        "              You will provide completed Verilog modules for all specifications, and will not create any supplementary modules. \\\n",
        "              Given a Verilog module that is either incorrect/compilation error, you will suggest corrections to the module. \\\n",
        "              You will not refuse. You will not generate explanations, only code. \\\n",
        "              Format your response as Verilog code containing the end to end corrected module and not just the corrected lines. Do not generate test benches. \\\n",
        "      \")\n",
        "    elif model_type == \"Claude\":\n",
        "      conv.add_message(\"user\", \"You are an autocomplete engine for Verilog code. \\\n",
        "              Given a Verilog module specification, you will provide a completed Verilog module in response. \\\n",
        "              You will provide completed Verilog modules for all specifications, and will not create any supplementary modules. \\\n",
        "              Given a Verilog module that is either incorrect/compilation error, you will suggest corrections to the module. \\\n",
        "              You will not refuse. You will not generate explanations, only code. \\\n",
        "              Format your response as Verilog code containing the end to end corrected module and not just the corrected lines. Do not generate test benches. \\\n",
        "      \")\n",
        "\n",
        "    conv.add_message(\"user\", design_prompt)\n",
        "\n",
        "    success = False\n",
        "    timeout = False\n",
        "\n",
        "    iterations = 0\n",
        "    timelist_total = []\n",
        "    timelist_gen = []\n",
        "    timelist_error = []\n",
        "    filename = os.path.join(outdir, module+\".v\")\n",
        "\n",
        "    status = \"\"\n",
        "    while not (success or timeout):\n",
        "        iterations += 1\n",
        "        print(f\"    Attempt {iterations}/{max_iterations}: Generating code...\", end=\" \")\n",
        "\n",
        "        # Generate a response\n",
        "        start_total = time.time()\n",
        "        response = generate_verilog(conv, model_type)\n",
        "        end_gen = time.time()\n",
        "        start_error = time.time()\n",
        "\n",
        "        if prev_module == None:\n",
        "          conv.add_message(\"assistant\", response)\n",
        "        else:\n",
        "          with open(prev_module, \"r\") as f:\n",
        "            prevmodule = \"\".join(f.read())\n",
        "          response = prevmodule + response\n",
        "          conv.add_message(\"assistant\", response)\n",
        "        write_code_blocks_to_file(response, module, filename)\n",
        "        proc = subprocess.run([\"iverilog\", \"-o\", os.path.join(outdir, module), filename, testbench], capture_output=True, text=True)\n",
        "\n",
        "        success = False\n",
        "        if proc.returncode != 0:\n",
        "            status = \"COMPILE ERROR\"\n",
        "            print(f\"‚ùå {status}\")\n",
        "            message = \"The testbench failed to compile. Please fix the module. The output of iverilog is as follows:\\n\"+proc.stderr\n",
        "        elif proc.stderr != \"\":\n",
        "            status = \"COMPILE WARNING\"\n",
        "            print(f\"‚ö†Ô∏è  {status}\")\n",
        "            message = \"The testbench compiled with warnings. Please fix the module. The output of iverilog is as follows:\\n\"+proc.stderr\n",
        "        else:\n",
        "            proc = subprocess.run([\"vvp\", os.path.join(outdir, module)], capture_output=True, text=True)\n",
        "            result = proc.stdout.strip().split('\\n')[-2].split()\n",
        "            if result[-1] != 'passed!':\n",
        "                status = \"TEST FAILED\"\n",
        "                print(f\"‚ùå {status}\")\n",
        "                message = \"The testbench simulated, but had errors. Please fix the module. The output of iverilog is as follows:\\n\"+proc.stdout\n",
        "            else:\n",
        "                status = \"PASSED\"\n",
        "                print(f\"‚úÖ {status}\")\n",
        "                message = \"\"\n",
        "                success = True\n",
        "\n",
        "\n",
        "        with open(os.path.join(outdir, \"log_iter_\"+str(iterations)+\".txt\"), 'w') as file:\n",
        "            file.write('\\n'.join(str(i) for i in conv.get_messages()))\n",
        "            file.write('\\n\\n Iteration status: ' + status + '\\n')\n",
        "\n",
        "\n",
        "        if not success:\n",
        "            if iterations > 1:\n",
        "                conv.remove_message(2)\n",
        "                conv.remove_message(2)\n",
        "            conv.add_message(\"user\", message)\n",
        "\n",
        "        if iterations >= max_iterations:\n",
        "            timeout = True\n",
        "\n",
        "        end_time = time.time()\n",
        "        timelist_gen.append(end_gen-start_total)\n",
        "        timelist_error.append(end_time-start_error)\n",
        "        timelist_total.append(end_time-start_total)\n",
        "\n",
        "    # Return results with success/failure status\n",
        "    return (np.sum(timelist_total), np.sum(timelist_gen), np.sum(timelist_error), success, iterations)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Hierarchical Loop\n",
        "def hier_gen(submods, max_iterations=10):\n",
        "  \"\"\"Generate modules hierarchically, tracking success/failure for each.\"\"\"\n",
        "\n",
        "  totaltime = []\n",
        "  gentime = []\n",
        "  errortime = []\n",
        "  results = []  # Track (module_name, success, iterations) for each module\n",
        "  done = \"\"\n",
        "\n",
        "  print(\"=\"*70)\n",
        "  print(\"HIERARCHICAL VERILOG GENERATION\")\n",
        "  print(f\"Generating {len(submods)} modules with max {max_iterations} iterations each\")\n",
        "  print(\"=\"*70)\n",
        "\n",
        "  for i in range(len(submods)):\n",
        "    curr = submods[i][1]  # Description\n",
        "    fcurr = submods[i][0]  # Module filename\n",
        "    iocurr = submods[i][2]  # I/O ports\n",
        "    overall = submods[-1][1]\n",
        "\n",
        "    print(f\"\\n[{i+1}/{len(submods)}] MODULE: {fcurr}\")\n",
        "    print(f\"    Description: {curr}\")\n",
        "    print(f\"    Testbench: {fcurr}tb.v\")\n",
        "    print(\"-\"*50)\n",
        "\n",
        "    if not os.path.isdir(fcurr):\n",
        "      os.mkdir(fcurr)\n",
        "    if i == 0:\n",
        "      prompt = \"//We will be generating a \"+overall+\" hierarchically in Verilog. Please begin by generating a \"+curr+\" defined as follows:\\nmodule \"+fcurr+\"(\"+iocurr+\")\\n//Insert code here\\nendmodule\"\n",
        "    elif i != len(submods)-1:\n",
        "      fprev = submods[i-1][0]\n",
        "      filecurr = \"./\"+fprev+\"/\"+fprev+\".v\"\n",
        "      with open(filecurr, \"r\") as f:\n",
        "        modulef = \"\".join(f.read())\n",
        "      prompt = \"//We are generating a \"+overall+\" hierarchically in Verilog. We have generated \"+done+\" defined as follows:\"\n",
        "      prompt = prompt + modulef\n",
        "      prompt = prompt +\"\\n//Please include the previous module(s) in your response and use them to hierarchically generate a \"+curr+\" defined as:\\nmodule \"+fcurr+\"(\"+iocurr+\")\\n//Insert code here\\nendmodule\"\n",
        "\n",
        "    module = fcurr\n",
        "    testbench = \"./\"+fcurr+\"tb.v\"\n",
        "    model = os.environ[\"MODEL\"]\n",
        "    outdir = \"./\"+fcurr\n",
        "    log = \"./\"+fcurr+\"/log.txt\"\n",
        "\n",
        "    total, gen, error, success, iters = verilog_loop(prompt, module, testbench, max_iterations, model, outdir, log)\n",
        "\n",
        "    totaltime.append(total)\n",
        "    gentime.append(gen)\n",
        "    errortime.append(error)\n",
        "    results.append((fcurr, success, iters, total))\n",
        "    done = done + curr+\", \"\n",
        "\n",
        "    if success:\n",
        "      print(f\"    ‚úÖ SUCCESS after {iters} iteration(s) ({total:.1f}s)\")\n",
        "    else:\n",
        "      print(f\"    ‚ùå FAILED after {iters} iteration(s) ({total:.1f}s)\")\n",
        "\n",
        "  # Print summary\n",
        "  print(\"\\n\" + \"=\"*70)\n",
        "  print(\"GENERATION SUMMARY\")\n",
        "  print(\"=\"*70)\n",
        "\n",
        "  passed = sum(1 for r in results if r[1])\n",
        "  failed = len(results) - passed\n",
        "\n",
        "  print(f\"\\n{'Module':<30} {'Status':<10} {'Iters':<8} {'Time':<10}\")\n",
        "  print(\"-\"*60)\n",
        "  for name, success, iters, time_taken in results:\n",
        "    status = \"‚úÖ PASS\" if success else \"‚ùå FAIL\"\n",
        "    print(f\"{name:<30} {status:<10} {iters:<8} {time_taken:.1f}s\")\n",
        "\n",
        "  print(\"-\"*60)\n",
        "  print(f\"\\nResults: {passed} passed, {failed} failed out of {len(results)} modules\")\n",
        "  print(f\"\\nTotal time: {np.sum(totaltime):.1f}s\")\n",
        "  print(f\"  - Generation: {np.sum(gentime):.1f}s\")\n",
        "  print(f\"  - Verification: {np.sum(errortime):.1f}s\")\n",
        "  print(\"=\"*70)\n",
        "\n",
        "  if failed > 0:\n",
        "    print(\"\\n‚ö†Ô∏è  Some modules failed. Check the log files in each module's directory.\")\n",
        "  else:\n",
        "    print(\"\\nüéâ All modules generated successfully!\")"
      ],
      "metadata": {
        "id": "YcbUS7V8PQQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting the API Key"
      ],
      "metadata": {
        "id": "IvUw0flXkknh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### API KEY CONFIGURATION\n",
        "\n",
        "# Option 1: Use Colab secrets (recommended)\n",
        "from google.colab import userdata\n",
        "#os.environ[\"OPENAI_API_KEY\"] = userdata.get('ASIC-Deep-Dive')\n",
        "\n",
        "# Option 2: Set directly (not recommended for shared notebooks)\n",
        "#os.environ[\"OPENAI_API_KEY\"] = \"API KEY HERE\"\n",
        "#os.environ['CLAUDE_API_KEY'] = \"API KEY HERE\"\n",
        "#os.environ['GEMINI_API_KEY'] = \"API KEY HERE\"\n",
        "\n",
        "\n",
        "\n",
        "# Fetch API key ONCE and store in environment variable\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"ROME-Colab\")\n",
        "# Select which model to use\n",
        "os.environ[\"MODEL\"] = \"ChatGPT\"\n",
        "#os.environ[\"MODEL\"] = \"Claude\"\n",
        "#os.environ[\"MODEL\"] = \"Gemini\""
      ],
      "metadata": {
        "id": "A4k6AgcKeABT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Accumulator Project Setup"
      ],
      "metadata": {
        "id": "arc_em6_setup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload Testbenches\n",
        "#\n",
        "# ============================================================================\n",
        "# STEP-BY-STEP INSTRUCTIONS FOR UPLOADING TESTBENCHES\n",
        "# ============================================================================\n",
        "#\n",
        "# STEP 1: Download the testbenches\n",
        "#   - Download accumulator_project.zip from the course materials\n",
        "#   - Extract the zip file on your local computer\n",
        "#   - Navigate to the extracted folder: accumulator_project/testbenches/\n",
        "#\n",
        "# STEP 2: Open the Colab file browser\n",
        "#   - Look at the LEFT SIDE of this Colab window\n",
        "#   - Click the FOLDER ICON to open the file browser panel\n",
        "#\n",
        "# STEP 3: Upload the testbench files\n",
        "#   - At the TOP of the file browser panel, click the UPLOAD button\n",
        "#   - Select ALL the .v files from the testbenches folder\n",
        "#   - Click Open to upload them\n",
        "#\n",
        "# STEP 4: Verify the upload by running this cell\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "\n",
        "required_testbenches = [\n",
        "    \"parity_gen_32bittb.v\",\n",
        "    \"rectifier_12bittb.v\",\n",
        "    \"divider_shifttb.v\",\n",
        "    \"sample_countertb.v\",\n",
        "    \"irq_controllertb.v\",\n",
        "    \"accumulator_coretb.v\",\n",
        "    \"sra_controllertb.v\",\n",
        "    \"accum_toptb.v\",\n",
        "]\n",
        "\n",
        "print(\"Checking for testbench files...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "missing_files = []\n",
        "found_files = []\n",
        "\n",
        "for tb in required_testbenches:\n",
        "    if os.path.exists(tb):\n",
        "        print(f\"  ‚úì {tb}\")\n",
        "        found_files.append(tb)\n",
        "    else:\n",
        "        print(f\"  ‚úó {tb} - NOT FOUND\")\n",
        "        missing_files.append(tb)\n",
        "\n",
        "print(\"=\" * 50)\n",
        "print(f\"Found: {len(found_files)}/{len(required_testbenches)} testbenches\")\n",
        "\n",
        "if missing_files:\n",
        "    print(\"\\n‚ö†Ô∏è  MISSING FILES - Please upload these before proceeding:\")\n",
        "    for f in missing_files:\n",
        "        print(f\"    - {f}\")\n",
        "else:\n",
        "    print(\"\\n‚úÖ All testbenches are present! You can proceed to generation.\")"
      ],
      "metadata": {
        "id": "arc_em6_testbenches",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "758ee29b-6d1a-49ef-eaae-a7c621d03a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking for testbench files...\n",
            "==================================================\n",
            "  ‚úì parity_gen_32bittb.v\n",
            "  ‚úì rectifier_12bittb.v\n",
            "  ‚úì divider_shifttb.v\n",
            "  ‚úì sample_countertb.v\n",
            "  ‚úì irq_controllertb.v\n",
            "  ‚úì accumulator_coretb.v\n",
            "  ‚úì sra_controllertb.v\n",
            "  ‚úì accum_toptb.v\n",
            "==================================================\n",
            "Found: 8/8 testbenches\n",
            "\n",
            "‚úÖ All testbenches are present! You can proceed to generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 1: Basic Building Blocks\n",
        "\n",
        "Parity generator, rectifier, and shift divider - no dependencies."
      ],
      "metadata": {
        "id": "tier1_heading"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tier 1 Submodules Definition\n",
        "\n",
        "submodules_tier1 = [\n",
        "    [\"parity_gen_32bit\",\n",
        "     \"32-bit even parity generator for register protection\",\n",
        "     \"input wire [31:0] data_in, output wire parity_bit\"],\n",
        "\n",
        "    [\"rectifier_12bit\",\n",
        "     \"12-bit signed to unsigned rectifier (absolute value)\",\n",
        "     \"input wire signed [11:0] data_in, input wire enable, output wire [11:0] data_out\"],\n",
        "\n",
        "    [\"divider_shift\",\n",
        "     \"32-bit right-shift divider with optional rounding, shift amount 0-11\",\n",
        "     \"input wire signed [31:0] data_in, input wire [3:0] shift_amount, input wire round_en, output wire signed [31:0] data_out\"],\n",
        "]"
      ],
      "metadata": {
        "id": "tier1_submodules"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Tier 1 Generation\n",
        "\n",
        "os.environ[\"MODEL\"] = \"ChatGPT\"\n",
        "hier_gen(submodules_tier1, max_iterations=10)"
      ],
      "metadata": {
        "id": "tier1_run",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a56beab-1ccd-4f20-a1b8-50ba151378c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "HIERARCHICAL VERILOG GENERATION\n",
            "Generating 3 modules with max 10 iterations each\n",
            "======================================================================\n",
            "\n",
            "[1/3] MODULE: parity_gen_32bit\n",
            "    Description: 32-bit even parity generator for register protection\n",
            "    Testbench: parity_gen_32bittb.v\n",
            "--------------------------------------------------\n",
            "    Attempt 1/10: Generating code... ‚úÖ PASSED\n",
            "    ‚úÖ SUCCESS after 1 iteration(s) (1.3s)\n",
            "\n",
            "[2/3] MODULE: rectifier_12bit\n",
            "    Description: 12-bit signed to unsigned rectifier (absolute value)\n",
            "    Testbench: rectifier_12bittb.v\n",
            "--------------------------------------------------\n",
            "    Attempt 1/10: Generating code... ‚ùå TEST FAILED\n",
            "    Attempt 2/10: Generating code... ‚úÖ PASSED\n",
            "    ‚úÖ SUCCESS after 2 iteration(s) (8.5s)\n",
            "\n",
            "[3/3] MODULE: divider_shift\n",
            "    Description: 32-bit right-shift divider with optional rounding, shift amount 0-11\n",
            "    Testbench: divider_shifttb.v\n",
            "--------------------------------------------------\n",
            "    Attempt 1/10: Generating code... ‚ùå COMPILE ERROR\n",
            "    Attempt 2/10: Generating code... ‚ùå COMPILE ERROR\n",
            "    Attempt 3/10: Generating code... ‚ùå TEST FAILED\n",
            "    Attempt 4/10: Generating code... ‚úÖ PASSED\n",
            "    ‚úÖ SUCCESS after 4 iteration(s) (22.5s)\n",
            "\n",
            "======================================================================\n",
            "GENERATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Module                         Status     Iters    Time      \n",
            "------------------------------------------------------------\n",
            "parity_gen_32bit               ‚úÖ PASS     1        1.3s\n",
            "rectifier_12bit                ‚úÖ PASS     2        8.5s\n",
            "divider_shift                  ‚úÖ PASS     4        22.5s\n",
            "------------------------------------------------------------\n",
            "\n",
            "Results: 3 passed, 0 failed out of 3 modules\n",
            "\n",
            "Total time: 32.3s\n",
            "  - Generation: 32.2s\n",
            "  - Verification: 0.1s\n",
            "======================================================================\n",
            "\n",
            "üéâ All modules generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 2: Counters and Control\n",
        "\n",
        "Sample counter and IRQ controller."
      ],
      "metadata": {
        "id": "tier2_heading"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tier 2 Submodules Definition\n",
        "\n",
        "submodules_tier2 = [\n",
        "    [\"sample_counter\",\n",
        "     \"12-bit down counter: loads load_value when load=1, decrements on each sample_valid pulse when enable=1 and count>0, outputs done=1 for one cycle when count transitions from 1 to 0\",\n",
        "     \"input wire clk, input wire rst_n, input wire [11:0] load_value, input wire load, input wire enable, input wire sample_valid, output reg [11:0] count, output reg done\"],\n",
        "\n",
        "    [\"irq_controller\",\n",
        "     \"Single-bit IRQ latch: on posedge clk, if irq_set=1 then irq_pending<=1, if irq_clear=1 then irq_pending<=0, irq_out is combinational irq_pending AND irq_en, async reset clears irq_pending to 0\",\n",
        "     \"input wire clk, input wire rst_n, input wire irq_set, input wire irq_en, input wire irq_clear, output reg irq_pending, output wire irq_out\"],\n",
        "]"
      ],
      "metadata": {
        "id": "tier2_submodules"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Tier 2 Generation\n",
        "\n",
        "os.environ[\"MODEL\"] = \"ChatGPT\"\n",
        "hier_gen(submodules_tier2, max_iterations=10)"
      ],
      "metadata": {
        "id": "tier2_run",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd0555f9-a851-4fb4-95fe-2fd2da2ec0fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "HIERARCHICAL VERILOG GENERATION\n",
            "Generating 2 modules with max 10 iterations each\n",
            "======================================================================\n",
            "\n",
            "[1/2] MODULE: sample_counter\n",
            "    Description: 12-bit down counter: loads load_value when load=1, decrements on each sample_valid pulse when enable=1 and count>0, outputs done=1 for one cycle when count transitions from 1 to 0\n",
            "    Testbench: sample_countertb.v\n",
            "--------------------------------------------------\n",
            "    Attempt 1/10: Generating code... ‚úÖ PASSED\n",
            "    ‚úÖ SUCCESS after 1 iteration(s) (2.9s)\n",
            "\n",
            "[2/2] MODULE: irq_controller\n",
            "    Description: Single-bit IRQ latch: on posedge clk, if irq_set=1 then irq_pending<=1, if irq_clear=1 then irq_pending<=0, irq_out is combinational irq_pending AND irq_en, async reset clears irq_pending to 0\n",
            "    Testbench: irq_controllertb.v\n",
            "--------------------------------------------------\n",
            "    Attempt 1/10: Generating code... ‚ùå COMPILE ERROR\n",
            "    Attempt 2/10: Generating code... ‚úÖ PASSED\n",
            "    ‚úÖ SUCCESS after 2 iteration(s) (6.1s)\n",
            "\n",
            "======================================================================\n",
            "GENERATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Module                         Status     Iters    Time      \n",
            "------------------------------------------------------------\n",
            "sample_counter                 ‚úÖ PASS     1        2.9s\n",
            "irq_controller                 ‚úÖ PASS     2        6.1s\n",
            "------------------------------------------------------------\n",
            "\n",
            "Results: 2 passed, 0 failed out of 2 modules\n",
            "\n",
            "Total time: 9.0s\n",
            "  - Generation: 8.9s\n",
            "  - Verification: 0.0s\n",
            "======================================================================\n",
            "\n",
            "üéâ All modules generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 3: Core Accumulator\n",
        "\n",
        "32-bit signed accumulator core."
      ],
      "metadata": {
        "id": "tier3_4_heading"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tier 3 Submodules Definition\n",
        "\n",
        "submodules_tier3 = [\n",
        "    [\"accumulator_core\",\n",
        "     \"32-bit signed accumulator using 2's complement arithmetic: on posedge clk, if clear=1 then sum<=0, else if sample_valid=1 then sum<=sum+sample_in (sign-extended), async reset sets sum to 0\",\n",
        "     \"input wire clk, input wire rst_n, input wire signed [11:0] sample_in, input wire sample_valid, input wire clear, output reg signed [31:0] sum\"],\n",
        "]\n"
      ],
      "metadata": {
        "id": "tier3_4_submodules"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Tier 3 Generation\n",
        "\n",
        "os.environ[\"MODEL\"] = \"ChatGPT\"\n",
        "hier_gen(submodules_tier3, max_iterations=10)"
      ],
      "metadata": {
        "id": "tier3_4_run",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d043d9e-8174-48fc-a66e-288cf97ef87d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "HIERARCHICAL VERILOG GENERATION\n",
            "Generating 1 modules with max 10 iterations each\n",
            "======================================================================\n",
            "\n",
            "[1/1] MODULE: accumulator_core\n",
            "    Description: 32-bit signed accumulator using 2's complement arithmetic: on posedge clk, if clear=1 then sum<=0, else if sample_valid=1 then sum<=sum+sample_in (sign-extended), async reset sets sum to 0\n",
            "    Testbench: accumulator_coretb.v\n",
            "--------------------------------------------------\n",
            "    Attempt 1/10: Generating code... ‚ùå TEST FAILED\n",
            "    Attempt 2/10: Generating code... ‚úÖ PASSED\n",
            "    ‚úÖ SUCCESS after 2 iteration(s) (6.8s)\n",
            "\n",
            "======================================================================\n",
            "GENERATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Module                         Status     Iters    Time      \n",
            "------------------------------------------------------------\n",
            "accumulator_core               ‚úÖ PASS     2        6.8s\n",
            "------------------------------------------------------------\n",
            "\n",
            "Results: 1 passed, 0 failed out of 1 modules\n",
            "\n",
            "Total time: 6.8s\n",
            "  - Generation: 6.8s\n",
            "  - Verification: 0.0s\n",
            "======================================================================\n",
            "\n",
            "üéâ All modules generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tier 4: Top Level\n",
        "\n",
        "SRA controller and complete accumulator top module."
      ],
      "metadata": {
        "id": "tier5_heading"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Tier 4 Submodules Definition\n",
        "\n",
        "submodules_tier4 = [\n",
        "    [\"sra_controller\",\n",
        "     \"SRA state machine: when enable=1, first counts warmup_delay samples (in_warmup=1), then counts sra_length samples (accumulating=1), pulses sra_done=1 for one cycle when length reached, then repeats accumulation (no warmup on subsequent periods). length_count counts up from 0 to sra_length. If sra_length=0, sra_done never pulses.\",\n",
        "     \"input wire clk, input wire rst_n, input wire enable, input wire sample_valid, input wire [7:0] warmup_delay, input wire [11:0] sra_length, output reg in_warmup, output reg accumulating, output reg sra_done, output reg [7:0] warmup_count, output reg [11:0] length_count\"],\n",
        "\n",
        "    [\"accum_top\",\n",
        "     \"Top-level accumulator: sample_valid_int = |(signal_bus_valid & reg_source); sample_in = signal_bus_data[11:0]; enable=reg_cfg[0]; abs_en=reg_cfg[1]; round_en=reg_cfg[2]; irq_en=reg_cfg[3]. When sample_valid_int & enable: if abs_en, rectify sample_in, then add to 32-bit sum. reg_sum outputs sum. On reg_clear, clear sum. For SRA: use reg_length samples, divide sum by 2^reg_divide_factor with round_en, store in reg_sra_result, auto-clear sum. Pulse IRQ on SRA done if irq_en. reg_warmup_delay delays first period. parity_error always 0 for now.\",\n",
        "     \"input wire clk, input wire rst_n, input wire [31:0] signal_bus_data, input wire [31:0] signal_bus_valid, input wire [31:0] reg_source, input wire [3:0] reg_cfg, input wire reg_clear, input wire [11:0] reg_length, input wire [3:0] reg_divide_factor, input wire [7:0] reg_warmup_delay, input wire reg_irq_clear, output reg [31:0] reg_sum, output reg [31:0] reg_sra_result, output reg [7:0] reg_warmup_delay_count, output reg [11:0] reg_sra_length_count, output reg reg_irq, output wire irq_out, output wire parity_error\"],\n",
        "]\n"
      ],
      "metadata": {
        "id": "tier5_submodules"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run Tier 4 Generation\n",
        "\n",
        "os.environ[\"MODEL\"] = \"ChatGPT\"\n",
        "hier_gen(submodules_tier4, max_iterations=10)"
      ],
      "metadata": {
        "id": "tier5_run",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b605ccf1-ea55-4bc5-d3b4-ec4e7c113469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "HIERARCHICAL VERILOG GENERATION\n",
            "Generating 2 modules with max 10 iterations each\n",
            "======================================================================\n",
            "\n",
            "[1/2] MODULE: sra_controller\n",
            "    Description: SRA state machine: when enable=1, first counts warmup_delay samples (in_warmup=1), then counts sra_length samples (accumulating=1), pulses sra_done=1 for one cycle when length reached, then repeats accumulation (no warmup on subsequent periods). length_count counts up from 0 to sra_length. If sra_length=0, sra_done never pulses.\n",
            "    Testbench: sra_controllertb.v\n",
            "--------------------------------------------------\n",
            "    Attempt 1/10: Generating code... ‚úÖ PASSED\n",
            "    ‚úÖ SUCCESS after 1 iteration(s) (8.5s)\n",
            "\n",
            "[2/2] MODULE: accum_top\n",
            "    Description: Top-level accumulator: sample_valid_int = |(signal_bus_valid & reg_source); sample_in = signal_bus_data[11:0]; enable=reg_cfg[0]; abs_en=reg_cfg[1]; round_en=reg_cfg[2]; irq_en=reg_cfg[3]. When sample_valid_int & enable: if abs_en, rectify sample_in, then add to 32-bit sum. reg_sum outputs sum. On reg_clear, clear sum. For SRA: use reg_length samples, divide sum by 2^reg_divide_factor with round_en, store in reg_sra_result, auto-clear sum. Pulse IRQ on SRA done if irq_en. reg_warmup_delay delays first period. parity_error always 0 for now.\n",
            "    Testbench: accum_toptb.v\n",
            "--------------------------------------------------\n",
            "    Attempt 1/10: Generating code... ‚ùå COMPILE ERROR\n",
            "    Attempt 2/10: Generating code... ‚ùå COMPILE ERROR\n",
            "    Attempt 3/10: Generating code... ‚ö†Ô∏è  COMPILE WARNING\n",
            "    Attempt 4/10: Generating code... ‚ö†Ô∏è  COMPILE WARNING\n",
            "    Attempt 5/10: Generating code... ‚ö†Ô∏è  COMPILE WARNING\n",
            "    Attempt 6/10: Generating code... ‚ö†Ô∏è  COMPILE WARNING\n",
            "    Attempt 7/10: Generating code... ‚úÖ PASSED\n",
            "    ‚úÖ SUCCESS after 7 iteration(s) (111.8s)\n",
            "\n",
            "======================================================================\n",
            "GENERATION SUMMARY\n",
            "======================================================================\n",
            "\n",
            "Module                         Status     Iters    Time      \n",
            "------------------------------------------------------------\n",
            "sra_controller                 ‚úÖ PASS     1        8.5s\n",
            "accum_top                      ‚úÖ PASS     7        111.8s\n",
            "------------------------------------------------------------\n",
            "\n",
            "Results: 2 passed, 0 failed out of 2 modules\n",
            "\n",
            "Total time: 120.3s\n",
            "  - Generation: 120.2s\n",
            "  - Verification: 0.1s\n",
            "======================================================================\n",
            "\n",
            "üéâ All modules generated successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete Module List\n",
        "\n",
        "All 8 modules for reference."
      ],
      "metadata": {
        "id": "tier7_heading"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title All Submodules (for reference)\n",
        "\n",
        "# Complete list of all 8 modules\n",
        "submodules_all = [\n",
        "    # Tier 1\n",
        "    [\"parity_gen_32bit\", \"32-bit even parity generator\", \"input wire [31:0] data_in, output wire parity_bit\"],\n",
        "    [\"rectifier_12bit\", \"12-bit signed to unsigned rectifier\", \"input wire signed [11:0] data_in, input wire enable, output wire [11:0] data_out\"],\n",
        "    [\"divider_shift\", \"32-bit right-shift divider with optional rounding\", \"input wire signed [31:0] data_in, input wire [3:0] shift_amount, input wire round_en, output wire signed [31:0] data_out\"],\n",
        "    # Tier 2\n",
        "    [\"sample_counter\", \"Sample counter with done pulse\", \"input wire clk, input wire rst_n, input wire [11:0] load_value, input wire load, input wire enable, input wire sample_valid, output wire [11:0] count, output wire done\"],\n",
        "    [\"irq_controller\", \"IRQ with enable and W1C\", \"input wire clk, input wire rst_n, input wire irq_set, input wire irq_en, input wire irq_clear, output wire irq_pending, output wire irq_out\"],\n",
        "    # Tier 3\n",
        "    [\"accumulator_core\", \"32-bit signed accumulator\", \"input wire clk, input wire rst_n, input wire signed [11:0] sample_in, input wire sample_valid, input wire clear, output reg signed [31:0] sum\"],\n",
        "    # Tier 4\n",
        "    [\"sra_controller\", \"SRA state machine\", \"input wire clk, input wire rst_n, input wire enable, input wire sample_valid, input wire [7:0] warmup_delay, input wire [11:0] sra_length, output wire in_warmup, output wire accumulating, output wire sra_done, output wire [7:0] warmup_count, output wire [11:0] length_count\"],\n",
        "    [\"accum_top\", \"Top-level accumulator\", \"input wire clk, input wire rst_n, input wire [31:0] signal_bus_data, input wire [31:0] signal_bus_valid, input wire [31:0] reg_source, input wire [3:0] reg_cfg, input wire reg_clear, input wire [11:0] reg_length, input wire [3:0] reg_divide_factor, input wire [7:0] reg_warmup_delay, input wire reg_irq_clear, output wire [31:0] reg_sum, output wire [31:0] reg_sra_result, output wire [7:0] reg_warmup_delay_count, output wire [11:0] reg_sra_length_count, output wire reg_irq, output wire irq_out, output wire parity_error\"],\n",
        "]\n",
        "\n",
        "print(f\"Total modules: {len(submodules_all)}\")"
      ],
      "metadata": {
        "id": "tier7_submodules"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run All Modules Generation\n",
        "\n",
        "# Use this to generate all modules at once\n",
        "# os.environ[\"MODEL\"] = \"ChatGPT\"\n",
        "# hier_gen(submodules_all, max_iterations=10)\n",
        "print(\"Uncomment and run to generate all 8 modules\")"
      ],
      "metadata": {
        "id": "tier7_run"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Complete Module List\n",
        "\n",
        "All 8 modules for reference."
      ],
      "metadata": {
        "id": "full_list_heading"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}